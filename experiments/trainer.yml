# checkout the documentation for more details
# https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api
# ------------------------
# device
accelerator: cpu
devices: auto

# ------------------------
# optimization
# gradient_clip_algorithm: value
# gradient_clip_val: 1.0
# precision: 16

# ------------------------
# limits & training loop controls
max_epochs: 600
log_every_n_steps: 1
check_val_every_n_epoch: 1

# ------------------------
# tracking & debugging
# track_grad_norm: inf
# logger is setup while initializing the trainer
enable_checkpointing: true # for faster training
enable_model_summary: true # for debugging
enable_progress_bar: false # for faster training

# ------------------------
# logger
logger:
  - class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: lightning_logs
      name: "autoencoder" # experiment name
      version: null # version number
      default_hp_metric: false
      log_graph: false # not supported with off-the-shelf lightning models
      prefix: ""
# ------------------------
# callbacks
callbacks:
  - class_path: src.callbacks.NoveltyAUROCCallback
    init_args:
      score_negative: true # use the negative sign of the objective as normal score

  - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    init_args:
      logging_interval: epoch
